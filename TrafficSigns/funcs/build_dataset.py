# %% import the necessary packages
from iou import compute_iou
import config
from bs4 import BeautifulSoup
from imutils import paths
import cv2
import os
import numpy as np

# %% loop over ther output positive and negative directories
for dirPath in (config.POSITIVE_PATH, config.NEGATIVE_PATH):
    # if the output directory does not exist yet, create it
    if not os.path.exists(dirPath):
        os.makedirs(dirPath)

# grab all image names in the input images directory
imagePaths = []
imageNames = []
for file in os.listdir(config.ORIG_IMAGES):
    if file.endswith(".ppm"):
        imageNames.append(file)
        imagePaths.append(os.path.join(config.ORIG_BASE_PATH, file))

# initialize the total number of positive and negative images we have
# saved to disk so far
totalPositive = 0
totalNegative = 0


# %% load the annotation file
annotations = np.loadtxt(config.ORIG_ANNOTS, dtype=str, delimiter=';')

# loop over the image paths
for (i, imagePath) in enumerate(imagePaths):
    # show a progress report
    print("[INFO] processing image {}/{}...".format(i + 1, len(imagePaths)))
    
    # initialize the list of ground-truth bounding boxes
    gtBoxes = []
    
    # extract the label and bounding box coordinates for the figure
    loc_bd_labels = np.where(annotations == imageNames[i])
    bd_labels = annotations [loc_bd_labels[0]]
    
    # %% loop over all 'object' elements
    for k in range(len(bd_labels)):
        # extract the label and bounding box coordinates
        label = bd_labels[k][5]
        xMin = int(bd_labels[k][1])
        yMin = int(bd_labels[k][2])
        xMax = int(bd_labels[k][3])
        yMax = int(bd_labels[k][4])

        # update our list of ground-truth bounding boxes
        gtBoxes.append((xMin, yMin, xMax, yMax))
    
    # load the input image from disk
    image = cv2.imread(imagePath)

    # extract the image dimensions
    (h, w, _) = image.shape
    # w - "width"
	# h - "height"
    
    # truncate any bounding box coordinates that may fall
    # outside the boundaries of the image
    xMin = max(0, xMin)
    yMin = max(0, yMin)
    xMax = min(w, xMax)
    yMax = min(h, yMax)

    # %%
    # %% SELECTIVE SEARCH
    # run selective search on the image and initialize our list of
	# proposed boxes
    ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()
    ss.setBaseImage(image)
    ss.switchToSelectiveSearchFast()
    rects = ss.process()
    proposedRects = []

    # loop over the rectangles generated by selective search
    for (x, y, w, h) in rects:
		# convert our bounding boxes from (x, y, w, h) to (startX,
		# startY, startX, endY)
        proposedRects.append((x, y, x + w, y + h))

    # %%
    # initialize counters used to count the number of positive and
	# negative ROIs saved thus far
    positiveROIs = 0
    negativeROIs = 0

    # loop over the maximum number of region proposals
    for proposedRect in proposedRects[:config.MAX_PROPOSALS]:
        # unpack the proposed rectangle bounding box
        (propStartX, propStartY, propEndX, propEndY) = proposedRect

        # loop over the ground-truth bounding boxes
        for gtBox in gtBoxes:
			# compute the intersection over union between the two
			# boxes and unpack the ground-truth bounding box
            iou = compute_iou(gtBox, proposedRect)
            (gtStartX, gtStartY, gtEndX, gtEndY) = gtBox

            # initialize the ROI and output path
            roi = None
            outputPath = None

            # %% check to see if the IOU is greater than 70% *and* that
			# we have not hit our positive count limit
            if iou > 0.7 and positiveROIs <= config.MAX_POSITIVE:
				# extract the ROI and then derive the output path to
				# the positive instance
                roi = image[propStartY:propEndY, propStartX:propEndX]
                filename = "{}.png".format(totalPositive)
                outputPath = os.path.sep.join([config.POSITIVE_PATH,filename])
				
                # increment the positive counters
                positiveROIs += 1
                totalPositive += 1
            
            # %% determine if the proposed bounding box falls *within*
			# the ground-truth bounding box
            fullOverlap = propStartX >= gtStartX
            fullOverlap = fullOverlap and propStartY >= gtStartY
            fullOverlap = fullOverlap and propEndX <= gtEndX
            fullOverlap = fullOverlap and propEndY <= gtEndY

            #%%  check to see if there is not full overlap *and* the IoU
			# is less than 5% *and* we have not hit our negative
			# count limit
            if not fullOverlap and iou < 0.05 and \
                negativeROIs <= config.MAX_NEGATIVE:
				# extract the ROI and then derive the output path to
				# the negative instance
                roi = image[propStartY:propEndY, propStartX:propEndX]
                filename = "{}.png".format(totalNegative)
                outputPath = os.path.sep.join([config.NEGATIVE_PATH,
                                   filename])
				
                # increment the negative counters
                negativeROIs += 1
                totalNegative += 1
            
            # %% check to see if both the ROI and output path are valid
            if roi is not None and outputPath is not None:
				# resize the ROI to the input dimensions of the CNN
				# that we'll be fine-tuning, then write the ROI to
				# disk
                roi = cv2.resize(roi, config.INPUT_DIMS,
                                interpolation=cv2.INTER_CUBIC)
                cv2.imwrite(outputPath, roi)






