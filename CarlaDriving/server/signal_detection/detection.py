import os
import imutils
import pickle
import cv2 as cv
import numpy as np
from server import core
from server.cv_utils import *
from server.signal_detection.nms import *

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.models import load_model

def init():
    model = load_model(core.app['RCNN_MODEL_PATH'])
    lb = pickle.loads(open(core.app['RCNN_MAP_PATH'], "rb").read())

    core.app['SIGNAL_RCNN_MODEL'] = model
    core.app['SIGNAL_RCNN_MAP'] = lb


def selectiveSearch(img):
    # run selective search on the image to generate bounding box proposal
    # regions
    ss = cv.ximgproc.segmentation.createSelectiveSearchSegmentation()
    ss.setBaseImage(img)
    ss.switchToSelectiveSearchFast()
    rects = ss.process()
    return rects

def generateBoxProposals(img,rects):
    #Go through a define number of boxes/proposals and get params (box coordinates)
    # initialize the list of region proposals that we'll be classifying
    # along with their associated bounding boxes
    proposals = []
    boxes = []

    # loop over the region proposal bounding box coordinates generated by
    # running selective search
    for (x, y, w, h) in rects[:core.app['RCNN_MAX_PROPOSALS']]:
        # extract the region from the input image, convert it from BGR to
        # RGB channel ordering, and then resize it to the required input
        # dimensions of our trained CNN
        roi = img[y:y + h, x:x + w]
        roi = cv.cvtColor(roi, cv.COLOR_BGR2RGB)
        roi = cv.resize(roi, core.app['RCNN_NET_DIM'],interpolation=cv.INTER_CUBIC)


        # further preprocess the ROI
        roi = img_to_array(roi)

        #image preprocess for mobile net v2
        roi = preprocess_input(roi)

        # update our proposals and bounding boxes lists
        proposals.append(roi)
        boxes.append((x, y, x + w, y + h))
    
    proposals = np.array(proposals, dtype="float32")
    boxes = np.array(boxes, dtype="int32")
    return proposals,boxes


def classify(proposals):
    probabilities = core.app['SIGNAL_RCNN_MODEL'].predict(proposals)
    return probabilities


def filterThreshold(boxes,probabilities):
    lb = core.app['SIGNAL_RCNN_MAP']
    # find the index of all predictions that are positive for the
    # "signal" class
    #Get max probability prediction index => get classes for that index
    #np.argmax(proba, axis=1) => find index of max probability for all proposals (returns list)
    #lb.classes_[np.argmax(proba, axis=1)] => will classify each proposal based on the max probability index
    positive_class_index = np.where(lb.classes_ == core.app['RCNN_POSITIVE_CLASS'])[0][0]
    labels = lb.classes_[np.argmax(probabilities, axis=1)]

    #Get only positive proposals => returns array
    idxs = np.where(labels == core.app['RCNN_POSITIVE_CLASS'])[0]
    #Get bounding boxes for only positive classes
    boxes = boxes[idxs]

    # label probabilities associated with the positive class (in our case positive class is )
    probabilities = probabilities[idxs][:, positive_class_index]


    #Minimum probability threshold
    idxs = np.where(probabilities >= core.app['RCNN_THRESHOLD'])
    boxes = boxes[idxs]
    probabilities = probabilities[idxs]

    return boxes,probabilities


def visualizeBeforeNMS(clone,boxes,probabilities,color=(0, 255, 0)):
    # loop over the bounding boxes and associated probabilities
    for (box, prob) in zip(boxes, probabilities):
        # draw the bounding box, label, and probability on the image
        (startX, startY, endX, endY) = box
        cv.rectangle(clone, (startX, startY), (endX, endY), color, 2)

        #Padding for class text
        y = startY - 10 if startY - 10 > 10 else startY + 10
        text=core.app['RCNN_POSITIVE_CLASS'].capitalize() + ": {:.2f}%".format(prob * 100)


        cv.putText(clone, text, (startX, y),cv.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)
    return clone


def visualizeAfterNMS(img,boxes,probabilities,threshold=0.3,color=(0, 255, 0)):
    boxIdxs = non_max_suppression(boxes, threshold)

    # loop over the bounding box indexes
    for i in boxIdxs:
        # draw the bounding box, label, and probability on the image
        (startX, startY, endX, endY) = boxes[i]

        cv.rectangle(img, (startX, startY), (endX, endY),color, 2)

        y = startY - 10 if startY - 10 > 10 else startY + 10
        text= core.app['RCNN_POSITIVE_CLASS'].capitalize() + ": {:.2f}%".format(probabilities[i] * 100)
        cv.putText(img, text, (startX, y),cv.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)
    return img

def detection(img,service):
    img = imutils.resize(img, width=500)#resizeImg(img,(service.screen_width,service.screen_height)) #imutils.resize(image, width=500)

    print("[INFO] running selective search...")
    rectangles = selectiveSearch(img)

    proposals,boxes = generateBoxProposals(img,rectangles)
    if len(boxes) < 1 or len(proposals) < 1:
        return img

    print("[INFO] classifying proposals...")
    probabilities = classify(proposals)

    print("[INFO] applying NMS...")
    boxes, probabilities = filterThreshold(boxes,probabilities)
    if len(boxes) < 1 or len(probabilities) < 1:
        return img
    print("[INFO] Show before NMS...")

    clone = img.copy()
    clone = visualizeBeforeNMS(clone,boxes,probabilities)
    clone = resizeImg(clone,(service.screen_width,service.screen_height))
    clone = convertRGB(clone)
    cv.imshow("Before NMS",clone)

    img = visualizeAfterNMS(img,boxes,probabilities,threshold=0.5)
    img = resizeImg(img,(service.screen_width,service.screen_height))
    img = convertRGB(img)
    cv.imshow("After NMS",img)

    return img



